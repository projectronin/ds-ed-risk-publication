{"cells":[{"cell_type":"code","source":["%pip install cloudpickle==1.6.0 keras==2.9 tensorflow==2.9 tensorflow-addons[tensorflow] scikit-learn==0.24.1"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"41a99f90-c13f-4ba6-85c5-0809b9e15226","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nLooking in indexes: https://repo.devops.projectronin.io/repository/ronin-pypi/simple/, https://repo.devops.projectronin.io/repository/pypi/simple/\nRequirement already satisfied: cloudpickle==1.6.0 in /databricks/python3/lib/python3.8/site-packages (1.6.0)\nCollecting keras==2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/keras/2.9.0/keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\nCollecting tensorflow==2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow/2.9.0/tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\nCollecting tensorflow-addons[tensorflow]\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-addons/0.18.0/tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting scikit-learn==0.24.1\n  Downloading https://repo.devops.projectronin.io/repository/pypi/packages/scikit-learn/0.24.1/scikit_learn-0.24.1-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.0.1)\nRequirement already satisfied: numpy&gt;=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.23.0)\nRequirement already satisfied: scipy&gt;=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.9.3)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (2.1.0)\nRequirement already satisfied: opt-einsum&gt;=2.3.2 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.3.0)\nCollecting tensorflow-estimator&lt;2.10.0,&gt;=2.9.0rc0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-estimator/2.9.0/tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (52.0.0)\nRequirement already satisfied: wrapt&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.12.1)\nCollecting absl-py&gt;=1.0.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/absl-py/1.3.0/absl_py-1.3.0-py3-none-any.whl (124 kB)\nRequirement already satisfied: six&gt;=1.12.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.15.0)\nRequirement already satisfied: keras-preprocessing&gt;=1.1.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.1.2)\nRequirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.39.0)\nRequirement already satisfied: typing-extensions&gt;=3.6.6 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.7.4.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (20.9)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.17.2)\nRequirement already satisfied: flatbuffers&lt;2,&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.12)\nRequirement already satisfied: h5py&gt;=2.9.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.1.0)\nRequirement already satisfied: termcolor&gt;=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.1.0)\nRequirement already satisfied: google-pasta&gt;=0.1.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (0.2.0)\nCollecting tensorboard&lt;2.10,&gt;=2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorboard/2.9.1/tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\nRequirement already satisfied: astunparse&gt;=1.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.6.3)\nCollecting tensorflow-io-gcs-filesystem&gt;=0.23.1\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-io-gcs-filesystem/0.28.0/tensorflow_io_gcs_filesystem-0.28.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\nCollecting libclang&gt;=13.0.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/libclang/14.0.6/libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\nRequirement already satisfied: gast&lt;=0.4.0,&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (0.4.0)\nRequirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /databricks/python3/lib/python3.8/site-packages (from astunparse&gt;=1.6.0-&gt;tensorflow==2.9) (0.36.2)\nRequirement already satisfied: markdown&gt;=2.6.8 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (3.3.3)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.0.1)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.4.2)\nRequirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.6.1)\nRequirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.22.1)\nCollecting requests&lt;3,&gt;=2.21.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/requests/2.28.1/requests-2.28.1-py3-none-any.whl (62 kB)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.8.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.2.8)\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (4.7.2)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (4.2.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.3.0)\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.4.8)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (2020.12.5)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.21.1)\nCollecting charset-normalizer&lt;3,&gt;=2\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/charset-normalizer/2.1.1/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (2.5)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (3.1.0)\nCollecting typeguard&gt;=2.7\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/typeguard/2.13.3/typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;tensorflow==2.9) (2.4.7)\nInstalling collected packages: charset-normalizer, requests, absl-py, typeguard, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, tensorflow-addons, tensorflow, scikit-learn\n  Attempting uninstall: requests\n    Found existing installation: requests 2.18.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;requests&#39;. No files were found to uninstall.\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.11.0\n    Not uninstalling absl-py at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;absl-py&#39;. No files were found to uninstall.\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Not uninstalling tensorflow-estimator at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;tensorflow-estimator&#39;. No files were found to uninstall.\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Not uninstalling tensorboard at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;tensorboard&#39;. No files were found to uninstall.\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Not uninstalling keras at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;keras&#39;. No files were found to uninstall.\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.1.1\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;scikit-learn&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-cpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\ntensorflow-cpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.23.0 which is incompatible.\nehr-featurize 0.0.0 requires requests==2.18.1, but you have requests 2.28.1 which is incompatible.\nehr-featurize 0.0.0 requires scikit-learn==1.1.1, but you have scikit-learn 0.24.1 which is incompatible.\nSuccessfully installed absl-py-1.3.0 charset-normalizer-2.1.1 keras-2.9.0 libclang-14.0.6 requests-2.28.1 scikit-learn-0.24.1 tensorboard-2.9.1 tensorflow-2.9.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.28.0 typeguard-2.13.3\nWARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nLooking in indexes: https://repo.devops.projectronin.io/repository/ronin-pypi/simple/, https://repo.devops.projectronin.io/repository/pypi/simple/\nRequirement already satisfied: cloudpickle==1.6.0 in /databricks/python3/lib/python3.8/site-packages (1.6.0)\nCollecting keras==2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/keras/2.9.0/keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\nCollecting tensorflow==2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow/2.9.0/tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\nCollecting tensorflow-addons[tensorflow]\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-addons/0.18.0/tensorflow_addons-0.18.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\nCollecting scikit-learn==0.24.1\n  Downloading https://repo.devops.projectronin.io/repository/pypi/packages/scikit-learn/0.24.1/scikit_learn-0.24.1-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\nRequirement already satisfied: joblib&gt;=0.11 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.0.1)\nRequirement already satisfied: numpy&gt;=1.13.3 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.23.0)\nRequirement already satisfied: scipy&gt;=0.19.1 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (1.9.3)\nRequirement already satisfied: threadpoolctl&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from scikit-learn==0.24.1) (2.1.0)\nRequirement already satisfied: opt-einsum&gt;=2.3.2 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.3.0)\nCollecting tensorflow-estimator&lt;2.10.0,&gt;=2.9.0rc0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-estimator/2.9.0/tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9) (52.0.0)\nRequirement already satisfied: wrapt&gt;=1.11.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.12.1)\nCollecting absl-py&gt;=1.0.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/absl-py/1.3.0/absl_py-1.3.0-py3-none-any.whl (124 kB)\nRequirement already satisfied: six&gt;=1.12.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.15.0)\nRequirement already satisfied: keras-preprocessing&gt;=1.1.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.1.2)\nRequirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.39.0)\nRequirement already satisfied: typing-extensions&gt;=3.6.6 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.7.4.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (20.9)\nRequirement already satisfied: protobuf&gt;=3.9.2 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.17.2)\nRequirement already satisfied: flatbuffers&lt;2,&gt;=1.12 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.12)\nRequirement already satisfied: h5py&gt;=2.9.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (3.1.0)\nRequirement already satisfied: termcolor&gt;=1.1.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.1.0)\nRequirement already satisfied: google-pasta&gt;=0.1.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (0.2.0)\nCollecting tensorboard&lt;2.10,&gt;=2.9\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorboard/2.9.1/tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\nRequirement already satisfied: astunparse&gt;=1.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (1.6.3)\nCollecting tensorflow-io-gcs-filesystem&gt;=0.23.1\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/tensorflow-io-gcs-filesystem/0.28.0/tensorflow_io_gcs_filesystem-0.28.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\nCollecting libclang&gt;=13.0.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/libclang/14.0.6/libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\nRequirement already satisfied: gast&lt;=0.4.0,&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from tensorflow==2.9) (0.4.0)\nRequirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /databricks/python3/lib/python3.8/site-packages (from astunparse&gt;=1.6.0-&gt;tensorflow==2.9) (0.36.2)\nRequirement already satisfied: markdown&gt;=2.6.8 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (3.3.3)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.0.1)\nRequirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.4.2)\nRequirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.6.1)\nRequirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.22.1)\nCollecting requests&lt;3,&gt;=2.21.0\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/requests/2.28.1/requests-2.28.1-py3-none-any.whl (62 kB)\nRequirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /databricks/python3/lib/python3.8/site-packages (from tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.8.0)\nRequirement already satisfied: pyasn1-modules&gt;=0.2.1 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.2.8)\nRequirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (4.7.2)\nRequirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (4.2.2)\nRequirement already satisfied: requests-oauthlib&gt;=0.7.0 in /databricks/python3/lib/python3.8/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.3.0)\nRequirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /databricks/python3/lib/python3.8/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (0.4.8)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (2020.12.5)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (1.21.1)\nCollecting charset-normalizer&lt;3,&gt;=2\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/charset-normalizer/2.1.1/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (2.5)\nRequirement already satisfied: oauthlib&gt;=3.0.0 in /databricks/python3/lib/python3.8/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;2.10,&gt;=2.9-&gt;tensorflow==2.9) (3.1.0)\nCollecting typeguard&gt;=2.7\n  Using cached https://repo.devops.projectronin.io/repository/pypi/packages/typeguard/2.13.3/typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;tensorflow==2.9) (2.4.7)\nInstalling collected packages: charset-normalizer, requests, absl-py, typeguard, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, libclang, keras, tensorflow-addons, tensorflow, scikit-learn\n  Attempting uninstall: requests\n    Found existing installation: requests 2.18.1\n    Not uninstalling requests at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;requests&#39;. No files were found to uninstall.\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 0.11.0\n    Not uninstalling absl-py at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;absl-py&#39;. No files were found to uninstall.\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.6.0\n    Not uninstalling tensorflow-estimator at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;tensorflow-estimator&#39;. No files were found to uninstall.\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.6.0\n    Not uninstalling tensorboard at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;tensorboard&#39;. No files were found to uninstall.\n  Attempting uninstall: keras\n    Found existing installation: keras 2.6.0\n    Not uninstalling keras at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;keras&#39;. No files were found to uninstall.\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.1.1\n    Not uninstalling scikit-learn at /databricks/python3/lib/python3.8/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb\n    Can&#39;t uninstall &#39;scikit-learn&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-cpu 2.6.0 requires absl-py~=0.10, but you have absl-py 1.3.0 which is incompatible.\ntensorflow-cpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.23.0 which is incompatible.\nehr-featurize 0.0.0 requires requests==2.18.1, but you have requests 2.28.1 which is incompatible.\nehr-featurize 0.0.0 requires scikit-learn==1.1.1, but you have scikit-learn 0.24.1 which is incompatible.\nSuccessfully installed absl-py-1.3.0 charset-normalizer-2.1.1 keras-2.9.0 libclang-14.0.6 requests-2.28.1 scikit-learn-0.24.1 tensorboard-2.9.1 tensorflow-2.9.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.28.0 typeguard-2.13.3\nWARNING: You are using pip version 21.0.1; however, version 22.3.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-cd803918-cb84-4aab-a765-c3c1770321bb/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## ED Insights performance calculations"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a4233f0-e86c-403f-bd2b-e3f6c20e07ae","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["#  keras==2.8.0\nimport sklearn\nimport pickle\nimport pandas as pd\nimport numpy as np\n# import shap\nimport json\nimport mlflow\nfrom mlflow.tracking import MlflowClient\nfrom datetime import datetime\nimport os\nimport keras\nfrom pyspark.sql import functions as F"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c1d2846-44c6-4511-af5d-8d98d324e76f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_train = spark.read.table('bhe.vae_knn_v42_train').toPandas()\nX_test = spark.read.table('bhe.vae_knn_v42_test').toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f6ca668d-397f-467b-af00-adb571b9fe36","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# prod data comes from separate table\n# filter by dates for consistency with past analyses\nX_prod = spark.read.table(\"bhe.vae_knn_v42_prod_results\").toPandas()\nX_prod['date'] = pd.to_datetime(X_prod['date'])\nX_prod = X_prod[\n  (X_prod['date'] > '2022-04-11')\n  & (X_prod['date'] < '2022-06-19')\n]\n\n# labels stored in separate table\nlabels = spark.read.table('monitoring_observability_gold.eri_n3_predictions_labels').filter(\n  F.col('model_version') == 35\n).toPandas()\nlabels['date'] = pd.to_datetime(labels['date'])\n\nX_prod['date'] = pd.to_datetime(X_prod['date'])\nlabels['date'] = pd.to_datetime(labels['date'])\n\n# prod features and labels\nX_prod = X_prod.merge(labels[['mrn', 'date', 'label']], on=['mrn', 'date'], how='left')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0193da24-5743-4d46-997d-064f188ebf66","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:92: UserWarning: toPandas attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  Unable to convert the field comorbidity_aidbox. If this column is not necessary, you may consider dropping it or converting to primitive type before the conversion.\nDirect cause: Unsupported type in conversion to Arrow: ArrayType(StructType(List(StructField(attribute,StringType,true),StructField(date,StringType,true))),true)\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:92: UserWarning: toPandas attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  Unable to convert the field comorbidity_aidbox. If this column is not necessary, you may consider dropping it or converting to primitive type before the conversion.\nDirect cause: Unsupported type in conversion to Arrow: ArrayType(StructType(List(StructField(attribute,StringType,true),StructField(date,StringType,true))),true)\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n/databricks/spark/python/pyspark/sql/pandas/conversion.py:194: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n  df[column_name] = series\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# load artifacts from trained model\n\nmodel_name = 'ED Predictions'\nmodel_version = 42\n\ndef load_artifacts(model_name='ED Prediction', model_version=42):\n    \"\"\"\n    Grab and return relevant artifacts for the given model + version.\n    \"\"\"\n    client = mlflow.tracking.MlflowClient()\n\n    artifact_dir = f\"./model-{model_version}\"\n    if not os.path.exists(artifact_dir):\n        os.mkdir(artifact_dir)\n    \n    loaded_model = mlflow.pyfunc.load_model(model_uri=f\"models:/{model_name}/{model_version}\")\n    local_path = client.download_artifacts(loaded_model._model_meta.run_id, \"model\", artifact_dir)\n    sklearn_model = loaded_model._model_impl.python_model.model\n    \n    X_train = pd.read_pickle(f'{artifact_dir}/model/artifacts/train_df.pkl')\n    X_test = pd.read_pickle(f'{artifact_dir}/model/artifacts/test_df.pkl')\n\n    with open(local_path + '/metadata.json') as f:\n        metadata = json.load(f)\n    \n    return {\"model\": sklearn_model, \"metadata\": metadata, \"train\": X_train, \"test\": X_test}\n  \nartifacts = load_artifacts()\nmetadata = artifacts['metadata']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"04fd4042-5247-442b-9dc3-06432458a2ff","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# race remapping\n# some racial groups are very sparse so they are collapsed into the \"other\" category\n\ndef race_vector_remap(df):\n  df['remap_race_vector_white_or_caucasian'] = df['race_vector_white_or_caucasian']\n  df['rempap_race_vector_black_or_african_american'] = df['race_vector_black_or_african_american']\n  df['remap_race_vector_asian'] = df['race_vector_asian']\n  df['remap_race_vector_other'] = ~df['race_vector_asian'].astype(bool) \\\n    & ~df['race_vector_black_or_african_american'].astype(bool) \\\n    & ~df['race_vector_white_or_caucasian'].astype(bool)\n  \n  return df\n\nX_train = race_vector_remap(X_train)\nX_test = race_vector_remap(X_test)\nX_prod = race_vector_remap(X_prod)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1137b5cd-e8b9-4732-ae93-fbee3f14c87d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Incident rates"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fd14d810-646a-4086-8882-b168da146547","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["X_train[metadata['label_col']].value_counts().loc[1], X_train[metadata['label_col']].value_counts(normalize=True).loc[1].round(4)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"969c5313-9549-4094-832f-30849d9fb76d","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[6]: (12719, 0.0865)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[6]: (12719, 0.0865)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_test[metadata['label_col']].value_counts().loc[1], X_test[metadata['label_col']].value_counts(normalize=True).loc[1].round(4)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"55530faa-8435-428d-a219-04584b7184ea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[7]: (3281, 0.0884)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: (3281, 0.0884)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_prod['label'].value_counts().loc[1], X_prod['label'].value_counts(normalize=True).loc[1].round(4)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7cf70f8a-9cbf-4103-a45f-f06dc5b3e82a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[8]: (1019, 0.0704)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[8]: (1019, 0.0704)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Dataset size"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7e255063-c101-4d6a-b48f-f1c4a1501de6","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["len(X_train), len(X_test), len(X_prod)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c60b2431-922d-46c6-815a-2dcc421bdf7a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[9]: (147023, 37115, 14465)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[9]: (147023, 37115, 14465)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_train['mrn'].nunique(), X_test['mrn'].nunique(), X_prod['mrn'].nunique()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f157882b-8608-4e72-b36a-85ace484411e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[10]: (22701, 5668, 7174)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[10]: (22701, 5668, 7174)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["(X_prod['date'].max() - X_prod['date'].min())"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b1098954-5fb0-462f-ae93-d9d1ced1e376","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[11]: Timedelta(&#39;67 days 00:00:00&#39;)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[11]: Timedelta(&#39;67 days 00:00:00&#39;)</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Demographic data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8439e1f1-fcfa-4bae-bced-7733ca27f053","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from collections import defaultdict\ndef get_demo_by_like(df_train, df_test, df_prod, like):\n  \"\"\"Get counts of rows in different dataframes by filtering subtext.\"\"\"\n  train, test, prod = defaultdict(list), defaultdict(list), defaultdict(list)\n  for c in [i for i in df_train.columns if like in i]:\n    train[c].append(len(df_train[df_train[c] == 1]))\n    test[c].append(len(df_test[df_test[c] == 1]))\n    prod[c].append(len(df_prod[df_prod[c] == 1]))\n  result = pd.concat([\n    pd.DataFrame(train),\n    pd.DataFrame(test),\n    pd.DataFrame(prod)\n  ], ignore_index=True)\n  result.index = ['train', 'test', 'prod']\n  \n  return result.T"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3681ee03-96cc-4a9b-8317-d6854cf0a2a9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train ,X_test, X_prod, 'birthsex')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2b6b09f1-9928-45f3-8e31-feff8b2eed7e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[13]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>199</td>\n      <td>13</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>77919</td>\n      <td>18611</td>\n      <td>6933</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>68711</td>\n      <td>18450</td>\n      <td>7516</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>199</td>\n      <td>13</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>77919</td>\n      <td>18611</td>\n      <td>6933</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>68711</td>\n      <td>18450</td>\n      <td>7516</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'remap_race_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ebb81959-9887-4108-af86-5e71164fe6a5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[14]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[14]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>110697</td>\n      <td>27251</td>\n      <td>11254</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>6498</td>\n      <td>1863</td>\n      <td>657</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>13522</td>\n      <td>3607</td>\n      <td>1132</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>110697</td>\n      <td>27251</td>\n      <td>11254</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>6498</td>\n      <td>1863</td>\n      <td>657</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>13522</td>\n      <td>3607</td>\n      <td>1132</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'ethnicity_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"01e4ed3e-d976-4975-aeb6-4e30d56356de","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>3253</td>\n      <td>638</td>\n      <td>325</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>122234</td>\n      <td>30442</td>\n      <td>12236</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>20850</td>\n      <td>5851</td>\n      <td>1902</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>3253</td>\n      <td>638</td>\n      <td>325</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>122234</td>\n      <td>30442</td>\n      <td>12236</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>20850</td>\n      <td>5851</td>\n      <td>1902</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'cancer_type')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"494d043e-59dc-44cc-89ee-63ff4c2b8cb6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[16]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[16]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cancer_type_breast-cancer</th>\n      <td>22551</td>\n      <td>6361</td>\n      <td>2231</td>\n    </tr>\n    <tr>\n      <th>cancer_type_prostate_cancer_combined</th>\n      <td>8006</td>\n      <td>1824</td>\n      <td>676</td>\n    </tr>\n    <tr>\n      <th>cancer_type_kidney_cancer_combined</th>\n      <td>7114</td>\n      <td>1693</td>\n      <td>519</td>\n    </tr>\n    <tr>\n      <th>cancer_type_bladder_cancer_combined</th>\n      <td>6106</td>\n      <td>1854</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>cancer_type_urethral_cancer_combined</th>\n      <td>2072</td>\n      <td>714</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>cancer_type_testicular_cancer_combined</th>\n      <td>1594</td>\n      <td>199</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>cancer_type_ureter_cancer_combined</th>\n      <td>822</td>\n      <td>194</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>cancer_type_penile_cancer_combined</th>\n      <td>366</td>\n      <td>61</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cancer_type_breast-cancer</th>\n      <td>22551</td>\n      <td>6361</td>\n      <td>2231</td>\n    </tr>\n    <tr>\n      <th>cancer_type_prostate_cancer_combined</th>\n      <td>8006</td>\n      <td>1824</td>\n      <td>676</td>\n    </tr>\n    <tr>\n      <th>cancer_type_kidney_cancer_combined</th>\n      <td>7114</td>\n      <td>1693</td>\n      <td>519</td>\n    </tr>\n    <tr>\n      <th>cancer_type_bladder_cancer_combined</th>\n      <td>6106</td>\n      <td>1854</td>\n      <td>397</td>\n    </tr>\n    <tr>\n      <th>cancer_type_urethral_cancer_combined</th>\n      <td>2072</td>\n      <td>714</td>\n      <td>344</td>\n    </tr>\n    <tr>\n      <th>cancer_type_testicular_cancer_combined</th>\n      <td>1594</td>\n      <td>199</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>cancer_type_ureter_cancer_combined</th>\n      <td>822</td>\n      <td>194</td>\n      <td>38</td>\n    </tr>\n    <tr>\n      <th>cancer_type_penile_cancer_combined</th>\n      <td>366</td>\n      <td>61</td>\n      <td>25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def cancer_type_enrich(df):\n  \"\"\"Enrich dataframe with additional cancer type info\"\"\"\n  \n  tmp_df = spark.createDataFrame(df)\n\n  tmp_cancer_enriched = spark.read.table(\n    'lauren_kerr_ad_hoc.enriched_cancer_type_from_conditions_problems'\n  ).select(\n    'mrn', F.col('cancer_group').alias('cancer_type')\n  ).filter(\n    (F.col('cancer_type') != 'AllCancerDiagnoses')\n  ).drop_duplicates()\n\n  tmp_df = tmp_df.join(tmp_cancer_enriched, on='mrn', how='left')\n  \n  return tmp_df.toPandas()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"65d528d0-fd64-4efd-a3d9-4fa8268a4a28","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_train_cancer_enriched = cancer_type_enrich(X_train)\nX_test_cancer_enriched = cancer_type_enrich(X_test)\nX_prod_cancer_enriched = cancer_type_enrich(X_prod)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"88d79b8b-286f-49a0-8ac9-05d000925b19","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:300: UserWarning: createDataFrame attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  A field of type StructType expects a pandas.DataFrame, but got: &lt;class &#39;pandas.core.series.Series&#39;&gt;\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/conversion.py:300: UserWarning: createDataFrame attempted Arrow optimization because &#39;spark.sql.execution.arrow.pyspark.enabled&#39; is set to true; however, failed by the reason below:\n  A field of type StructType expects a pandas.DataFrame, but got: &lt;class &#39;pandas.core.series.Series&#39;&gt;\nAttempting non-optimization as &#39;spark.sql.execution.arrow.pyspark.fallback.enabled&#39; is set to true.\n  warnings.warn(msg)\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["# departmental count\npd.DataFrame(\n  X_train_cancer_enriched['cancer_type'].value_counts(dropna=False)\n).rename(columns={'cancer_type': 'train'}).join(\n  pd.DataFrame(\n    X_test_cancer_enriched['cancer_type'].value_counts(dropna=False)\n  ).rename(columns={'cancer_type': 'test'})\n).join(\n  pd.DataFrame(\n    X_prod_cancer_enriched['cancer_type'].value_counts(dropna=False)\n  ).rename(columns={'cancer_type': 'prod'})\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"98d3ed4f-190c-467e-b1a3-a73b375b00fb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[19]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[19]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>GU Cancer</th>\n      <td>74215</td>\n      <td>17744</td>\n      <td>5837</td>\n    </tr>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>51507</td>\n      <td>14027</td>\n      <td>5626</td>\n    </tr>\n    <tr>\n      <th>None</th>\n      <td>22693</td>\n      <td>5614</td>\n      <td>3101</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>GU Cancer</th>\n      <td>74215</td>\n      <td>17744</td>\n      <td>5837</td>\n    </tr>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>51507</td>\n      <td>14027</td>\n      <td>5626</td>\n    </tr>\n    <tr>\n      <th>None</th>\n      <td>22693</td>\n      <td>5614</td>\n      <td>3101</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Lab/medical info"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b481e014-bce3-479f-b617-045737bfb3b1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'm_value_pathologic_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7cdf50e-d3f0-49e9-ba65-146b04b1f232","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[20]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[20]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>m_value_pathologic_vector_1</th>\n      <td>6862</td>\n      <td>1754</td>\n      <td>777</td>\n    </tr>\n    <tr>\n      <th>m_value_pathologic_vector_0</th>\n      <td>22935</td>\n      <td>5955</td>\n      <td>2707</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>m_value_pathologic_vector_1</th>\n      <td>6862</td>\n      <td>1754</td>\n      <td>777</td>\n    </tr>\n    <tr>\n      <th>m_value_pathologic_vector_0</th>\n      <td>22935</td>\n      <td>5955</td>\n      <td>2707</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'm_value_clinical_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a28d1114-517a-433c-9e56-89644e1f482a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[21]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[21]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>m_value_clinical_vector_1</th>\n      <td>16605</td>\n      <td>4155</td>\n      <td>1541</td>\n    </tr>\n    <tr>\n      <th>m_value_clinical_vector_0</th>\n      <td>29260</td>\n      <td>7361</td>\n      <td>3831</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>m_value_clinical_vector_1</th>\n      <td>16605</td>\n      <td>4155</td>\n      <td>1541</td>\n    </tr>\n    <tr>\n      <th>m_value_clinical_vector_0</th>\n      <td>29260</td>\n      <td>7361</td>\n      <td>3831</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 't_value_pathologic_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"440d99a0-44c4-4025-aec9-c6867a8ae520","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[22]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[22]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_value_pathologic_vector_4</th>\n      <td>1515</td>\n      <td>523</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_3</th>\n      <td>5080</td>\n      <td>1548</td>\n      <td>572</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_2</th>\n      <td>7216</td>\n      <td>1495</td>\n      <td>786</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_1</th>\n      <td>10300</td>\n      <td>2729</td>\n      <td>1136</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_0</th>\n      <td>1849</td>\n      <td>490</td>\n      <td>279</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_value_pathologic_vector_4</th>\n      <td>1515</td>\n      <td>523</td>\n      <td>302</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_3</th>\n      <td>5080</td>\n      <td>1548</td>\n      <td>572</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_2</th>\n      <td>7216</td>\n      <td>1495</td>\n      <td>786</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_1</th>\n      <td>10300</td>\n      <td>2729</td>\n      <td>1136</td>\n    </tr>\n    <tr>\n      <th>t_value_pathologic_vector_0</th>\n      <td>1849</td>\n      <td>490</td>\n      <td>279</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 't_value_clinical_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ab0d1711-328e-4e7b-a6d3-aa1a17bc09b5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[23]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[23]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_value_clinical_vector_4</th>\n      <td>6019</td>\n      <td>1616</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_3</th>\n      <td>7671</td>\n      <td>1823</td>\n      <td>956</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_2</th>\n      <td>13553</td>\n      <td>3313</td>\n      <td>1685</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_1</th>\n      <td>9651</td>\n      <td>2528</td>\n      <td>1113</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_0</th>\n      <td>969</td>\n      <td>297</td>\n      <td>184</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>t_value_clinical_vector_4</th>\n      <td>6019</td>\n      <td>1616</td>\n      <td>664</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_3</th>\n      <td>7671</td>\n      <td>1823</td>\n      <td>956</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_2</th>\n      <td>13553</td>\n      <td>3313</td>\n      <td>1685</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_1</th>\n      <td>9651</td>\n      <td>2528</td>\n      <td>1113</td>\n    </tr>\n    <tr>\n      <th>t_value_clinical_vector_0</th>\n      <td>969</td>\n      <td>297</td>\n      <td>184</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'n_value_pathologic_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d66326c0-78fa-48ad-a8c1-e2899e607fa3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[24]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[24]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n_value_pathologic_vector_3</th>\n      <td>1993</td>\n      <td>669</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_2</th>\n      <td>2995</td>\n      <td>630</td>\n      <td>440</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_1</th>\n      <td>7465</td>\n      <td>1667</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_0</th>\n      <td>13673</td>\n      <td>3807</td>\n      <td>1460</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n_value_pathologic_vector_3</th>\n      <td>1993</td>\n      <td>669</td>\n      <td>299</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_2</th>\n      <td>2995</td>\n      <td>630</td>\n      <td>440</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_1</th>\n      <td>7465</td>\n      <td>1667</td>\n      <td>889</td>\n    </tr>\n    <tr>\n      <th>n_value_pathologic_vector_0</th>\n      <td>13673</td>\n      <td>3807</td>\n      <td>1460</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'n_value_clinical_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3bd05471-8a6a-4c3a-a77e-11ddc960f3a6","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[25]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[25]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n_value_clinical_vector_3</th>\n      <td>4880</td>\n      <td>1165</td>\n      <td>649</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_2</th>\n      <td>2297</td>\n      <td>562</td>\n      <td>259</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_1</th>\n      <td>11790</td>\n      <td>2779</td>\n      <td>1390</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_0</th>\n      <td>19758</td>\n      <td>5099</td>\n      <td>2496</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>n_value_clinical_vector_3</th>\n      <td>4880</td>\n      <td>1165</td>\n      <td>649</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_2</th>\n      <td>2297</td>\n      <td>562</td>\n      <td>259</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_1</th>\n      <td>11790</td>\n      <td>2779</td>\n      <td>1390</td>\n    </tr>\n    <tr>\n      <th>n_value_clinical_vector_0</th>\n      <td>19758</td>\n      <td>5099</td>\n      <td>2496</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_by_like(X_train, X_test, X_prod, 'comorbidity')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4dfbbd72-b845-452b-95db-a0ce3532efdc","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[26]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[26]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>comorbidity_blood_loss_anemia</th>\n      <td>18271</td>\n      <td>4809</td>\n      <td>1688</td>\n    </tr>\n    <tr>\n      <th>comorbidity_fluid-electrolyte_disorder</th>\n      <td>15267</td>\n      <td>3850</td>\n      <td>1317</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypertension</th>\n      <td>18484</td>\n      <td>4916</td>\n      <td>1609</td>\n    </tr>\n    <tr>\n      <th>comorbidity_weight_loss</th>\n      <td>9074</td>\n      <td>1972</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>comorbidity_cardiac_arrhythmia</th>\n      <td>7578</td>\n      <td>1874</td>\n      <td>688</td>\n    </tr>\n    <tr>\n      <th>comorbidity_anemia</th>\n      <td>6933</td>\n      <td>1817</td>\n      <td>732</td>\n    </tr>\n    <tr>\n      <th>comorbidity_diabetes_uncomplicated</th>\n      <td>6467</td>\n      <td>1749</td>\n      <td>699</td>\n    </tr>\n    <tr>\n      <th>comorbidity_renal_failure</th>\n      <td>6540</td>\n      <td>1628</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypothyroidism</th>\n      <td>7183</td>\n      <td>1926</td>\n      <td>723</td>\n    </tr>\n    <tr>\n      <th>comorbidity_depression</th>\n      <td>5896</td>\n      <td>1526</td>\n      <td>528</td>\n    </tr>\n    <tr>\n      <th>comorbidity_coagulopathy</th>\n      <td>4377</td>\n      <td>1153</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>comorbidity_diabetes_complicated</th>\n      <td>3954</td>\n      <td>1017</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>comorbidity_pulmonary_circulation_disorder</th>\n      <td>3132</td>\n      <td>856</td>\n      <td>258</td>\n    </tr>\n    <tr>\n      <th>comorbidity_obesity</th>\n      <td>3033</td>\n      <td>852</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>comorbidity_chronic_pulmonary_disease</th>\n      <td>2965</td>\n      <td>762</td>\n      <td>291</td>\n    </tr>\n    <tr>\n      <th>comorbidity_liver_disease</th>\n      <td>2289</td>\n      <td>741</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>comorbidity_congestive_heart_failure</th>\n      <td>2112</td>\n      <td>545</td>\n      <td>194</td>\n    </tr>\n    <tr>\n      <th>comorbidity_neurological_disorders</th>\n      <td>1763</td>\n      <td>480</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>comorbidity_paralysis</th>\n      <td>1860</td>\n      <td>505</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>comorbidity_valvular_disease</th>\n      <td>1198</td>\n      <td>225</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>comorbidity_peripheral_vascular_disorder</th>\n      <td>1216</td>\n      <td>366</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>comorbidity_rheumatoid_arthritis</th>\n      <td>891</td>\n      <td>289</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypertension_complicated</th>\n      <td>771</td>\n      <td>199</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>comorbidity_psychoses</th>\n      <td>626</td>\n      <td>207</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>comorbidity_alcohol_abuse</th>\n      <td>402</td>\n      <td>154</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>comorbidity_drug_abuse</th>\n      <td>273</td>\n      <td>77</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>comorbidity_aids_hiv</th>\n      <td>160</td>\n      <td>7</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>comorbidity_peptic_ulcer_disease</th>\n      <td>136</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>train</th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>comorbidity_blood_loss_anemia</th>\n      <td>18271</td>\n      <td>4809</td>\n      <td>1688</td>\n    </tr>\n    <tr>\n      <th>comorbidity_fluid-electrolyte_disorder</th>\n      <td>15267</td>\n      <td>3850</td>\n      <td>1317</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypertension</th>\n      <td>18484</td>\n      <td>4916</td>\n      <td>1609</td>\n    </tr>\n    <tr>\n      <th>comorbidity_weight_loss</th>\n      <td>9074</td>\n      <td>1972</td>\n      <td>758</td>\n    </tr>\n    <tr>\n      <th>comorbidity_cardiac_arrhythmia</th>\n      <td>7578</td>\n      <td>1874</td>\n      <td>688</td>\n    </tr>\n    <tr>\n      <th>comorbidity_anemia</th>\n      <td>6933</td>\n      <td>1817</td>\n      <td>732</td>\n    </tr>\n    <tr>\n      <th>comorbidity_diabetes_uncomplicated</th>\n      <td>6467</td>\n      <td>1749</td>\n      <td>699</td>\n    </tr>\n    <tr>\n      <th>comorbidity_renal_failure</th>\n      <td>6540</td>\n      <td>1628</td>\n      <td>525</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypothyroidism</th>\n      <td>7183</td>\n      <td>1926</td>\n      <td>723</td>\n    </tr>\n    <tr>\n      <th>comorbidity_depression</th>\n      <td>5896</td>\n      <td>1526</td>\n      <td>528</td>\n    </tr>\n    <tr>\n      <th>comorbidity_coagulopathy</th>\n      <td>4377</td>\n      <td>1153</td>\n      <td>391</td>\n    </tr>\n    <tr>\n      <th>comorbidity_diabetes_complicated</th>\n      <td>3954</td>\n      <td>1017</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>comorbidity_pulmonary_circulation_disorder</th>\n      <td>3132</td>\n      <td>856</td>\n      <td>258</td>\n    </tr>\n    <tr>\n      <th>comorbidity_obesity</th>\n      <td>3033</td>\n      <td>852</td>\n      <td>183</td>\n    </tr>\n    <tr>\n      <th>comorbidity_chronic_pulmonary_disease</th>\n      <td>2965</td>\n      <td>762</td>\n      <td>291</td>\n    </tr>\n    <tr>\n      <th>comorbidity_liver_disease</th>\n      <td>2289</td>\n      <td>741</td>\n      <td>204</td>\n    </tr>\n    <tr>\n      <th>comorbidity_congestive_heart_failure</th>\n      <td>2112</td>\n      <td>545</td>\n      <td>194</td>\n    </tr>\n    <tr>\n      <th>comorbidity_neurological_disorders</th>\n      <td>1763</td>\n      <td>480</td>\n      <td>146</td>\n    </tr>\n    <tr>\n      <th>comorbidity_paralysis</th>\n      <td>1860</td>\n      <td>505</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>comorbidity_valvular_disease</th>\n      <td>1198</td>\n      <td>225</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>comorbidity_peripheral_vascular_disorder</th>\n      <td>1216</td>\n      <td>366</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>comorbidity_rheumatoid_arthritis</th>\n      <td>891</td>\n      <td>289</td>\n      <td>80</td>\n    </tr>\n    <tr>\n      <th>comorbidity_hypertension_complicated</th>\n      <td>771</td>\n      <td>199</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>comorbidity_psychoses</th>\n      <td>626</td>\n      <td>207</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>comorbidity_alcohol_abuse</th>\n      <td>402</td>\n      <td>154</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>comorbidity_drug_abuse</th>\n      <td>273</td>\n      <td>77</td>\n      <td>44</td>\n    </tr>\n    <tr>\n      <th>comorbidity_aids_hiv</th>\n      <td>160</td>\n      <td>7</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>comorbidity_peptic_ulcer_disease</th>\n      <td>136</td>\n      <td>12</td>\n      <td>7</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Performance"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"79c89ce8-2198-4e7c-af9f-185a63dc8e07","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# test & prod performance\nsklearn.metrics.roc_auc_score(\n  X_test[metadata['label_col']], X_test['prediction']\n), sklearn.metrics.roc_auc_score(\n  X_prod['label'], X_prod['candidate_predicted_risk']\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64cbb824-8caf-48c6-a7c5-f7f3c21c96d0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[29]: (0.7958312008553801, 0.7568702462231435)</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[29]: (0.7958312008553801, 0.7568702462231435)</div>"]}}],"execution_count":0},{"cell_type":"code","source":["def get_demo_perf_by_like(df_test, df_prod, like):\n  \"\"\"Calcualte AUC on test and prod data filtering columns by subtext\"\"\"\n  test, prod = defaultdict(list), defaultdict(list)\n  for c in [i for i in df_test.columns if like in i]:\n    tmp_test = df_test[df_test[c] == 1]\n    try:\n      auc_test = sklearn.metrics.roc_auc_score(tmp_test[metadata['label_col']], tmp_test['prediction'])\n    except ValueError:\n      auc_test = -99\n      \n    tmp_prod = df_prod[df_prod[c] == 1]\n    try:\n      auc_prod = sklearn.metrics.roc_auc_score(tmp_prod['label'], tmp_prod['candidate_predicted_risk'])\n    except ValueError:\n      auc_prod = -99\n      \n    test[c].append(auc_test)\n    prod[c].append(auc_prod)\n    \n  result = pd.concat([\n    pd.DataFrame(test),\n    pd.DataFrame(prod)\n  ], ignore_index=True)\n  result.index = ['test', 'prod']\n  return result.T\n\n\ndef get_demo_perf_by_like_bootstrap(df_test, df_prod, like):\n  \"\"\"Calcualte bootstrapped AUC on test and prod data filtering columns by subtext\"\"\"\n  test, prod = defaultdict(list), defaultdict(list)\n  for c in [i for i in df_test.columns if like in i]:\n    tmp_test = df_test[df_test[c] == 1]\n    tmp_prod = df_prod[df_prod[c] == 1]\n    \n    tests = []\n    prods = []\n    \n    for _ in range(2000):\n      tmp_test_bs = tmp_test.sample(frac=1, replace=True)\n      tmp_prod_bs = tmp_prod.sample(frac=1, replace=True)\n      try:\n        tests.append(sklearn.metrics.roc_auc_score(tmp_test_bs[metadata['label_col']], tmp_test_bs['prediction']))\n      except ValueError:\n        tests.append(np.nan)\n      try:\n        prods.append(sklearn.metrics.roc_auc_score(tmp_prod_bs['label'], tmp_prod_bs['candidate_predicted_risk']))\n      except ValueError:\n        prods.append(np.nan)\n      \n    test[c].append(f\"{np.round(np.mean(tests) - (np.std(tests) * 2), 2), np.round(np.mean(tests) + (np.std(tests) * 2), 2)}\")\n    prod[c].append(f\"{np.round(np.mean(prods) - (np.std(prods) * 2), 2), np.round(np.mean(prods) + (np.std(prods) * 2), 2)}\")\n    \n  result = pd.concat([\n    pd.DataFrame(test),\n    pd.DataFrame(prod)\n  ], ignore_index=True)\n  result.index = ['test', 'prod']\n  return result.T\n  \n    # print(f\"{c:<80} {auc_test:>20} {auc_prod:>20}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9df1fb1c-94aa-4286-b9de-a49c3ce67ee2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like(X_test, X_prod, 'birthsex')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9ccf43bb-6ee8-4af6-b33b-ac68c0d812e4","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[34]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[34]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>-99.000000</td>\n      <td>0.416667</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>0.794758</td>\n      <td>0.776841</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>0.793777</td>\n      <td>0.739818</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>-99.000000</td>\n      <td>0.416667</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>0.794758</td>\n      <td>0.776841</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>0.793777</td>\n      <td>0.739818</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like_bootstrap(X_test, X_prod, 'birthsex')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"039ee1d4-a3ec-4933-a758-b71945c5b504","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[35]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[35]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>(nan, nan)</td>\n      <td>(nan, nan)</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>(0.78, 0.81)</td>\n      <td>(0.75, 0.8)</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>(0.78, 0.81)</td>\n      <td>(0.72, 0.76)</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>birthsex_vector_unk</th>\n      <td>(nan, nan)</td>\n      <td>(nan, nan)</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_m</th>\n      <td>(0.78, 0.81)</td>\n      <td>(0.75, 0.8)</td>\n    </tr>\n    <tr>\n      <th>birthsex_vector_f</th>\n      <td>(0.78, 0.81)</td>\n      <td>(0.72, 0.76)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like(X_test, X_prod, 'remap_race_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c9cd86f-1ea5-404b-93e3-c9aefca529e9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[36]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[36]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>0.788626</td>\n      <td>0.755048</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>0.768082</td>\n      <td>0.777283</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>0.796017</td>\n      <td>0.763102</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>0.788626</td>\n      <td>0.755048</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>0.768082</td>\n      <td>0.777283</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>0.796017</td>\n      <td>0.763102</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like_bootstrap(X_test, X_prod, 'remap_race_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6680e5ca-e2d5-4e3f-86ba-99b28b07d769","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[37]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[37]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>(0.78, 0.8)</td>\n      <td>(0.74, 0.77)</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>(0.73, 0.81)</td>\n      <td>(0.71, 0.85)</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>(0.77, 0.82)</td>\n      <td>(0.71, 0.82)</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>remap_race_vector_white_or_caucasian</th>\n      <td>(0.78, 0.8)</td>\n      <td>(0.74, 0.77)</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_asian</th>\n      <td>(0.73, 0.81)</td>\n      <td>(0.71, 0.85)</td>\n    </tr>\n    <tr>\n      <th>remap_race_vector_other</th>\n      <td>(0.77, 0.82)</td>\n      <td>(0.71, 0.82)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like(X_test, X_prod, 'ethnicity_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d539dea7-b19e-4a63-8eb4-a37d4036b849","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[38]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[38]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>0.769402</td>\n      <td>0.819435</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>0.793106</td>\n      <td>0.761831</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>0.807038</td>\n      <td>0.711785</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>0.769402</td>\n      <td>0.819435</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>0.793106</td>\n      <td>0.761831</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>0.807038</td>\n      <td>0.711785</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like_bootstrap(X_test, X_prod, 'ethnicity_vector')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0139a44-811c-43f2-8620-6c39a24131d8","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[39]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[39]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>(0.69, 0.84)</td>\n      <td>(0.74, 0.9)</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>(0.78, 0.8)</td>\n      <td>(0.74, 0.78)</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>(0.79, 0.83)</td>\n      <td>(0.66, 0.77)</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>ethnicity_vector_unknown</th>\n      <td>(0.69, 0.84)</td>\n      <td>(0.74, 0.9)</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_not_hispanic_or_latino</th>\n      <td>(0.78, 0.8)</td>\n      <td>(0.74, 0.78)</td>\n    </tr>\n    <tr>\n      <th>ethnicity_vector_hispanic_or_latino</th>\n      <td>(0.79, 0.83)</td>\n      <td>(0.66, 0.77)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["get_demo_perf_by_like(X_test, X_prod, 'cancer_type')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4a8646f6-59df-4ef3-8d52-419e9f7b3731","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[40]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[40]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cancer_type_breast-cancer</th>\n      <td>0.791149</td>\n      <td>0.725873</td>\n    </tr>\n    <tr>\n      <th>cancer_type_prostate_cancer_combined</th>\n      <td>0.820376</td>\n      <td>0.728067</td>\n    </tr>\n    <tr>\n      <th>cancer_type_kidney_cancer_combined</th>\n      <td>0.726157</td>\n      <td>0.715468</td>\n    </tr>\n    <tr>\n      <th>cancer_type_bladder_cancer_combined</th>\n      <td>0.684930</td>\n      <td>0.687032</td>\n    </tr>\n    <tr>\n      <th>cancer_type_urethral_cancer_combined</th>\n      <td>0.710586</td>\n      <td>0.621979</td>\n    </tr>\n    <tr>\n      <th>cancer_type_testicular_cancer_combined</th>\n      <td>0.766760</td>\n      <td>0.529070</td>\n    </tr>\n    <tr>\n      <th>cancer_type_ureter_cancer_combined</th>\n      <td>0.527155</td>\n      <td>0.338542</td>\n    </tr>\n    <tr>\n      <th>cancer_type_penile_cancer_combined</th>\n      <td>-99.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>cancer_type_breast-cancer</th>\n      <td>0.791149</td>\n      <td>0.725873</td>\n    </tr>\n    <tr>\n      <th>cancer_type_prostate_cancer_combined</th>\n      <td>0.820376</td>\n      <td>0.728067</td>\n    </tr>\n    <tr>\n      <th>cancer_type_kidney_cancer_combined</th>\n      <td>0.726157</td>\n      <td>0.715468</td>\n    </tr>\n    <tr>\n      <th>cancer_type_bladder_cancer_combined</th>\n      <td>0.684930</td>\n      <td>0.687032</td>\n    </tr>\n    <tr>\n      <th>cancer_type_urethral_cancer_combined</th>\n      <td>0.710586</td>\n      <td>0.621979</td>\n    </tr>\n    <tr>\n      <th>cancer_type_testicular_cancer_combined</th>\n      <td>0.766760</td>\n      <td>0.529070</td>\n    </tr>\n    <tr>\n      <th>cancer_type_ureter_cancer_combined</th>\n      <td>0.527155</td>\n      <td>0.338542</td>\n    </tr>\n    <tr>\n      <th>cancer_type_penile_cancer_combined</th>\n      <td>-99.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from collections import defaultdict\ndef groupby_auc(df_test, df_prod, col):\n  \"\"\"Calculate AUC using groupby\"\"\"\n  test = defaultdict(list)\n  for name, group in df_test.groupby(col):\n    test[col].append(name)\n    test['auc_test'].append(\n      sklearn.metrics.roc_auc_score(group[metadata['label_col']], group['prediction'])\n    )\n    \n  prod = defaultdict(list)\n  for name, group in df_prod.groupby(col):\n    prod[col].append(name)\n    prod['auc_prod'].append(\n      sklearn.metrics.roc_auc_score(group['label'], group['candidate_predicted_risk'])\n    )\n  \n  return pd.DataFrame(test).set_index(col).join(\n    pd.DataFrame(prod).set_index(col)\n  ).rename(columns={'auc_test': 'test', 'auc_prod': 'prod'})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ab1ec3d3-2d57-45b3-b1fc-b3aab1cc0939","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["groupby_auc(X_test_cancer_enriched, X_prod_cancer_enriched, 'cancer_type')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"dbcced65-77af-4acb-854f-0fe2a2569d7b","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[42]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[42]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>cancer_type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>0.799973</td>\n      <td>0.733487</td>\n    </tr>\n    <tr>\n      <th>GU Cancer</th>\n      <td>0.779924</td>\n      <td>0.762549</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>cancer_type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>0.799973</td>\n      <td>0.733487</td>\n    </tr>\n    <tr>\n      <th>GU Cancer</th>\n      <td>0.779924</td>\n      <td>0.762549</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from collections import defaultdict\ndef groupby_auc_bootstrap(df_test, df_prod, col):\n  \"\"\"Calculate bootsrapped AUC using groupby\"\"\"\n  test = defaultdict(list)\n  for name, group in df_test.groupby(col):\n    test[col].append(name)\n    \n    tests = []\n    for _ in range(2000):\n      tmp_test_bs = group.sample(frac=1, replace=True)\n      try:\n        tests.append(sklearn.metrics.roc_auc_score(tmp_test_bs[metadata['label_col']], tmp_test_bs['prediction']))\n      except ValueError:\n        tests.append(np.nan)\n        \n    test['auc_test'].append(\n      f\"{np.round(np.mean(tests) - (np.std(tests) * 2), 2), np.round(np.mean(tests) + (np.std(tests) * 2), 2)}\"\n    )\n    \n  prod = defaultdict(list)\n  for name, group in df_prod.groupby(col):\n    prod[col].append(name)\n    \n    prods = []\n    for _ in range(2000):\n      tmp_prob_bs = group.sample(frac=1, replace=True)\n      try:\n        prods.append(sklearn.metrics.roc_auc_score(tmp_prob_bs['label'], tmp_prob_bs['candidate_predicted_risk']))\n      except ValueError:\n        prods.append(np.nan)\n        \n    test['auc_prod'].append(\n      f\"{np.round(np.mean(prods) - (np.std(prods) * 2), 2), np.round(np.mean(prods) + (np.std(prods) * 2), 2)}\"\n    )\n  \n  return pd.DataFrame(test).set_index(col).join(\n    pd.DataFrame(prod).set_index(col)\n  ).rename(columns={'auc_test': 'test', 'auc_prod': 'prod'})"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"204ee6eb-d67e-4d37-9e30-d9cc85f5e3f3","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["groupby_auc_bootstrap(X_test_cancer_enriched, X_prod_cancer_enriched, 'cancer_type')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8c64a0a0-dfc3-44e4-8852-4f635a4342ed","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[44]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[44]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>cancer_type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>(0.79, 0.81)</td>\n      <td>(0.71, 0.76)</td>\n    </tr>\n    <tr>\n      <th>GU Cancer</th>\n      <td>(0.77, 0.79)</td>\n      <td>(0.74, 0.79)</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>cancer_type</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Breast Cancer</th>\n      <td>(0.79, 0.81)</td>\n      <td>(0.71, 0.76)</td>\n    </tr>\n    <tr>\n      <th>GU Cancer</th>\n      <td>(0.77, 0.79)</td>\n      <td>(0.74, 0.79)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["X_test_cancer_enriched['dummy_pivot'] = 1\nX_prod_cancer_enriched['dummy_pivot'] = 1\ngroupby_auc_bootstrap(X_test_cancer_enriched, X_prod_cancer_enriched, 'dummy_pivot')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7ccaab1-0db9-496c-8744-621d8ef4688a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[45]: </div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[45]: </div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>dummy_pivot</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>(0.79, 0.8)</td>\n      <td>(0.74, 0.77)</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n      <th>prod</th>\n    </tr>\n    <tr>\n      <th>dummy_pivot</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>(0.79, 0.8)</td>\n      <td>(0.74, 0.77)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e37f41fe-6611-41f8-b935-8863db64172b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ed_insights_metadata_performance","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":1938602282932781,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":2364243842557442}},"nbformat":4,"nbformat_minor":0}
